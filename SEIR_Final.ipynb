{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SEIR\n",
    "def f(y, t, theta, sigma, gamma):\n",
    "    S, E, I, R = y\n",
    "    N = S + E + I + R \n",
    "\n",
    "    dS = -theta * S * I/N\n",
    "    dE = theta * S * I/N - sigma * E\n",
    "    dI = sigma * E - gamma * I\n",
    "    dR = gamma * I\n",
    "    return np.array([dS, dE, dI, dR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobianas para sensitividades\n",
    "J = autograd.jacobian(f, argnum=0)\n",
    "\n",
    "grad_theta0 = autograd.jacobian(f, argnum=2)\n",
    "grad_sigma  = autograd.jacobian(f, argnum=4)\n",
    "grad_gamma  = autograd.jacobian(f, argnum=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobianas para sensitividades\n",
    "J = autograd.jacobian(f, argnum=0)\n",
    "grad_theta = autograd.jacobian(f, argnum=2)\n",
    "grad_sigma = autograd.jacobian(f, argnum=3)\n",
    "grad_gamma = autograd.jacobian(f, argnum=4)\n",
    "\n",
    "def ODESYS(Y, t, theta, sigma, gamma):\n",
    "    dy_dt = f(Y[:4], t, theta, sigma, gamma)\n",
    "\n",
    "    sensitivities = Y[4:].reshape(4, 3)\n",
    "    \n",
    "    grad = J(Y[:4], t, theta, sigma, gamma) @ sensitivities + np.stack([\n",
    "        grad_theta(Y[:4], t, theta, sigma, gamma),\n",
    "        grad_sigma(Y[:4], t, theta, sigma, gamma),\n",
    "        grad_gamma(Y[:4], t, theta, sigma, gamma)\n",
    "    ], axis=1)\n",
    "    \n",
    "    return np.concatenate([dy_dt, grad.flatten()])\n",
    "\n",
    "def Cost(y_obs):\n",
    "    def cost(Y):\n",
    "        n = y_obs.shape[0]\n",
    "        err = np.linalg.norm(y_obs - Y, 2, axis=1)\n",
    "        return np.mean(err)/n\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados sintéticos\n",
    "np.random.seed(19920908)\n",
    "Y0 = np.concatenate([np.array([0.97, 0.0, 0.01, 0.0]), np.zeros(12)])  # 12 para sensitividades (4x3)\n",
    "t_span = (0, 15)\n",
    "t_eval = np.linspace(*t_span, 101)\n",
    "true_theta, true_sigma, true_gamma = 2.0, 0.8, 0.3\n",
    "\n",
    "sol = solve_ivp(\n",
    "    lambda t, y: ODESYS(y, t, true_theta, true_sigma, true_gamma),\n",
    "    t_span, Y0, t_eval=t_eval, method='RK45'\n",
    ")\n",
    "\n",
    "y_obs = sol.y[:4].T + np.random.normal(0, 0.05, size=sol.y[:4].T.shape)\n",
    "# Plot observações\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(t_eval, y_obs[:, 0], marker=\".\", alpha=0.5, label=\"S\")\n",
    "plt.scatter(t_eval, y_obs[:, 1], marker=\".\", alpha=0.5, label=\"E\")\n",
    "plt.scatter(t_eval, y_obs[:, 2], marker=\".\", alpha=0.5, label=\"I\")\n",
    "plt.scatter(t_eval, y_obs[:, 3], marker=\".\", alpha=0.5, label=\"R\")\n",
    "plt.legend()\n",
    "plt.title(\"Observações do modelo SEIR\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Proporção da população\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente descendente com busca linear\n",
    "theta, sigma, gamma = 1.5, 1.0, 0.1  # Chute inicial\n",
    "\n",
    "print(f\"Valores verdadeiros: θ0={true_theta:.4f}, σ={true_sigma:.4f}, gamma={true_gamma:.4f}\")\n",
    "print(f\"Chute inicial:       θ0={theta:.4f}, σ={sigma:.4f}, gamma={gamma:.4f}\")\n",
    "\n",
    "cost = Cost(y_obs)\n",
    "grad_c = autograd.grad(cost)\n",
    "\n",
    "maxiter = 100\n",
    "prev_cost = 1\n",
    "tolerance = 1e-6\n",
    "error_history = []\n",
    "par_history = []\n",
    "alpha_history = []\n",
    "\n",
    "def line_search(theta, sigma, gamma, grad, sensitivities, Y, current_cost):\n",
    "    alpha = 1.0\n",
    "    beta = 0.2\n",
    "    c = 1e-4\n",
    "    new_cost = 2*current_cost\n",
    "\n",
    "    s = c / np.linalg.norm(grad(Y))**2\n",
    "    new_sensitivities = sensitivities\n",
    "\n",
    "    while (new_cost > current_cost) and (s > 1e-10):\n",
    "        s *= beta\n",
    "\n",
    "        new_theta = theta - s * (grad(Y) * new_sensitivities[:, :, 0]).sum()\n",
    "        new_sigma  = sigma  - s * (grad(Y) * new_sensitivities[:, :, 1]).sum()\n",
    "        new_gamma  = gamma  - s * (grad(Y) * new_sensitivities[:, :, 2]).sum()\n",
    "\n",
    "        sol = solve_ivp(\n",
    "            lambda t, y: ODESYS(y, t, new_theta, new_sigma, new_gamma),\n",
    "            t_span, Y0, t_eval=t_eval, method='RK45'\n",
    "        )\n",
    "        Y_new = sol.y[:4].T\n",
    "        new_cost = cost(Y_new)\n",
    "        new_sensitivities = sol.y[4:].T.reshape(-1, 4, 3)\n",
    "\n",
    "    new_new_theta = new_theta - s * (grad(Y_new) * new_sensitivities[:, :, 0]).sum()\n",
    "    new_new_sigma = new_sigma - s * (grad(Y_new) * new_sensitivities[:, :, 1]).sum()\n",
    "    new_new_gamma = new_gamma - s * (grad(Y_new) * new_sensitivities[:, :, 2]).sum()\n",
    "\n",
    "    sol = solve_ivp(\n",
    "        lambda t, y: ODESYS(y, t, new_new_theta, new_new_sigma, new_new_gamma),\n",
    "        t_span, Y0, t_eval=t_eval, method='RK45'\n",
    "    )\n",
    "    Y_new_new = sol.y[:4].T\n",
    "    new_new_cost = cost(Y_new_new)\n",
    "\n",
    "    div1 = (new_cost - current_cost) / s\n",
    "    div2 = (new_new_cost -2*new_cost + current_cost)/(2*s*s)\n",
    "    alpha = 0.5 * (s - div1/div2)\n",
    "    \n",
    "    if alpha < 0:\n",
    "        alpha = s\n",
    "\n",
    "    return alpha\n",
    "\n",
    "for i in range(maxiter):\n",
    "    sol = solve_ivp(\n",
    "        lambda t, y: ODESYS(y, t, theta, sigma, gamma),\n",
    "        t_span, Y0, t_eval=t_eval, method='RK45'\n",
    "    )\n",
    "    Y = sol.y[:4].T\n",
    "\n",
    "    sensitivities = sol.y[4:].T.reshape(-1, 4, 3)\n",
    "\n",
    "    current_cost = cost(Y)\n",
    "\n",
    "    error_history.append(current_cost)\n",
    "    par_history.append((theta, sigma, gamma))\n",
    "    alpha_history.append(0.0)\n",
    "\n",
    "    if abs((current_cost - prev_cost)/prev_cost) < tolerance and i > 0:\n",
    "        print(f\"Convergiu na iteração {i}\")\n",
    "        break\n",
    "\n",
    "    prev_cost = current_cost\n",
    "\n",
    "    alpha = line_search(theta, sigma, gamma, grad_c, sensitivities, Y, current_cost)\n",
    "\n",
    "    theta -= alpha * (grad_c(Y) * sensitivities[:, :, 0]).sum()\n",
    "    sigma  -= alpha * (grad_c(Y) * sensitivities[:, :, 1]).sum()\n",
    "    gamma  -= alpha * (grad_c(Y) * sensitivities[:, :, 2]).sum()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Iter {i}: theta={theta:.4f}, sigma={sigma:.4f}, gamma={gamma:.4f}, alpha={alpha:.4f}, current_cost={current_cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"RESULTADOS FINAIS:\")\n",
    "print(f\"Valores verdadeiros: θ={true_theta:.4f}, σ={true_sigma:.4f}, gamma={true_gamma:.4f}\")\n",
    "print(f\"Valores estimados:   θ={theta:.4f}, σ={sigma:.4f}, gamma={gamma:.4f}\")\n",
    "print(f\"Erro θ: {abs(theta - true_theta)/true_theta*100:.2f}%\")\n",
    "print(f\"Erro σ: {abs(sigma - true_sigma)/true_sigma*100:.2f}%\")\n",
    "print(f\"Erro gamma: {abs(gamma - true_gamma)/true_gamma*100:.2f}%\")\n",
    "print(f\"Custo final: {current_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dos dados observados vs modelo final\n",
    "sol_final = solve_ivp(\n",
    "    lambda t, y: ODESYS(y, t, theta, sigma, gamma),\n",
    "    t_span, Y0, t_eval=t_eval, method='RK45'\n",
    ")\n",
    "y_final = sol_final.y[:4].T\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(t_eval, y_obs[:, 0], alpha=0.7, label='S (observado)', color='blue', s=10)\n",
    "plt.scatter(t_eval, y_obs[:, 1], alpha=0.7, label='E (observado)', color='orange', s=10)\n",
    "plt.scatter(t_eval, y_obs[:, 2], alpha=0.7, label='I (observado)', color='red', s=10)\n",
    "plt.scatter(t_eval, y_obs[:, 3], alpha=0.7, label='R (observado)', color='green', s=10)\n",
    "\n",
    "plt.plot(t_eval, y_final[:, 0], '--', label='S (modelo)', color='darkblue', linewidth=2)\n",
    "plt.plot(t_eval, y_final[:, 1], '--', label='E (modelo)', color='darkorange', linewidth=2)\n",
    "plt.plot(t_eval, y_final[:, 2], '--', label='I (modelo)', color='darkred', linewidth=2)\n",
    "plt.plot(t_eval, y_final[:, 3], '--', label='R (modelo)', color='darkgreen', linewidth=2)\n",
    "\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Proporção da população')\n",
    "plt.title('Dados observados vs Modelo ajustado')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da evolução dos parâmetros durante a otimização\n",
    "par_history = np.array(par_history)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# Subplot 1: xi (antigo theta)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(par_history[:, 0], 'b-', linewidth=2, marker='o', markersize=4)\n",
    "plt.axhline(y=true_theta, color='r', linestyle='--', linewidth=2, label=f'Verdadeiro: {true_theta:.4f}')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Xi(ξ)')\n",
    "plt.title('Evolução de xi(ξ)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: sigma\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(par_history[:, 1], 'g-', linewidth=2, marker='s', markersize=4)\n",
    "plt.axhline(y=true_sigma, color='r', linestyle='--', linewidth=2, label=f'Verdadeiro: {true_sigma:.4f}')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Sigma(σ)')\n",
    "plt.title('Evolução de Sigma(σ)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: gamma\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(par_history[:, 2], 'm-', linewidth=2, marker='^', markersize=4)\n",
    "plt.axhline(y=true_gamma, color='r', linestyle='--', linewidth=2, label=f'Verdadeiro: {true_gamma:.4f}')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Gamma(γ)')\n",
    "plt.title('Evolução de gamma(γ)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
