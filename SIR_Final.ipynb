{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SIR com theta variando\n",
    "def f(y, t, theta, sigma):\n",
    "\n",
    "    S, I, R = y\n",
    "    N = S + I + R \n",
    "\n",
    "    dS = -theta  * S * I/N\n",
    "    dI = theta  * S * I/N - sigma * I\n",
    "    dR = sigma * I\n",
    "    return np.array([dS, dI, dR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobianas para sensitividades\n",
    "J = autograd.jacobian(f, argnum=0)\n",
    "grad_theta = autograd.jacobian(f, argnum=2)\n",
    "grad_sigma  = autograd.jacobian(f, argnum=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODESYS(Y, t, theta, sigma):\n",
    "    dy_dt = f(Y[:3], t, theta, sigma)\n",
    "\n",
    "    sensitivities = Y[3:].reshape(3, 2)\n",
    "    \n",
    "    grad = J(Y[:3], t, theta, sigma) @ sensitivities + np.stack([\n",
    "        grad_theta(Y[:3], t, theta, sigma),\n",
    "        grad_sigma(Y[:3], t, theta, sigma)\n",
    "    ], axis=1)\n",
    "    \n",
    "    return np.concatenate([dy_dt, grad.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(y_obs):\n",
    "    def cost(Y):\n",
    "        n = y_obs.shape[0] # Pegar o número de observações, ou seja, as linhas.\n",
    "        err = np.linalg.norm(y_obs - Y, 2, axis=1)\n",
    "        return np.mean(err)/n\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19920908)\n",
    "# 3 states + 3×2 sensitivities = 9 total variables\n",
    "Y0 = np.concatenate([np.array([0.97, 0.01, 0.0]), np.zeros(6)])  \n",
    "\n",
    "t_span = (0, 15)\n",
    "t_eval = np.linspace(*t_span, 101)\n",
    "true_theta, true_sigma = 2.8, 1.7  # True parameter values\n",
    "\n",
    "sol = solve_ivp(\n",
    "    lambda t, y: ODESYS(y, t, true_theta, true_sigma),\n",
    "    t_span, Y0, t_eval=t_eval, method='RK45')\n",
    "\n",
    "y_obs = sol.y[:3].T + np.random.normal(0, 0.05, size=sol.y[:3].T.shape)\n",
    "\n",
    "# Plot observações\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(t_eval, y_obs[:, 0], marker=\".\", alpha=0.5, label=\"S\")\n",
    "plt.scatter(t_eval, y_obs[:, 1], marker=\".\", alpha=0.5, label=\"I\")\n",
    "plt.scatter(t_eval, y_obs[:, 2], marker=\".\", alpha=0.5, label=\"R\")\n",
    "plt.legend()\n",
    "plt.title(\"Observações do modelo SIR\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Proporção da população\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Gradiente descendente com busca linear\n",
    "theta, sigma = 1.8, 1.0  # Chute inicial (apenas 2 parâmetros)\n",
    "print(f\"Valores verdadeiros: θ={true_theta:.4f}, σ={true_sigma:.4f}\")\n",
    "print(f\"Chute inicial:       θ={theta:.4f}, σ={sigma:.4f}\")\n",
    "\n",
    "cost = Cost(y_obs)\n",
    "grad_c = autograd.grad(cost)\n",
    "\n",
    "maxiter = 100\n",
    "prev_cost = 1\n",
    "tolerance = 1e-6\n",
    "error_history = []\n",
    "par_history = []\n",
    "alpha_history = []\n",
    "\n",
    "def line_search(theta, sigma, grad, sensitivities, Y, current_cost):\n",
    "    alpha = 1.0  # Tamanho inicial do passo\n",
    "    beta = 0.2   # Fator de redução\n",
    "    c = 1e-4     # Constante para a condição\n",
    "    new_cost = 2*current_cost\n",
    "\n",
    "    s = c / np.linalg.norm(grad(Y))**2\n",
    "    new_sensitivities = sensitivities\n",
    "\n",
    "    while (new_cost > current_cost) and (s > 1e-10):\n",
    "        # Reduzir o tamanho do passo\n",
    "        s *= beta\n",
    "\n",
    "        # Atualizar os parâmetros com o tamanho do passo atual (apenas 2 parâmetros)\n",
    "        new_theta = theta - s * (grad(Y) * new_sensitivities[:, :, 0]).sum()\n",
    "        new_sigma = sigma - s * (grad(Y) * new_sensitivities[:, :, 1]).sum()\n",
    "\n",
    "        \n",
    "        # Resolver o sistema com os novos parâmetros\n",
    "        sol = solve_ivp(\n",
    "            lambda t, y: ODESYS(y, t, new_theta, new_sigma),\n",
    "            t_span, Y0, t_eval=t_eval, method='RK45'\n",
    "        )\n",
    "\n",
    "        Y_new = sol.y[:3].T\n",
    "        new_cost = cost(Y_new)\n",
    "        new_sensitivities = sol.y[3:].T.reshape(-1, 3, 2)  # 3 states × 2 parameters\n",
    "\n",
    "    # Segunda avaliação para interpolação quadrática\n",
    "    new_new_theta = new_theta - s * (grad(Y_new) * new_sensitivities[:, :, 0]).sum()\n",
    "    new_new_sigma = new_sigma - s * (grad(Y_new) * new_sensitivities[:, :, 1]).sum()\n",
    "\n",
    "    # Resolver o sistema com os novos parâmetros\n",
    "    sol = solve_ivp(\n",
    "        lambda t, y: ODESYS(y, t, new_new_theta, new_new_sigma),\n",
    "        t_span, Y0, t_eval=t_eval, method='RK45')\n",
    "    \n",
    "    Y_new_new = sol.y[:3].T\n",
    "    new_new_cost = cost(Y_new_new)\n",
    "\n",
    "    # Interpolação quadrática para encontrar o passo ótimo\n",
    "    div1 = (new_cost - current_cost) / s\n",
    "    div2 = (new_new_cost - 2*new_cost + current_cost)/(2*s*s)\n",
    "    alpha = 0.5 * (s - div1/div2)\n",
    "    \n",
    "    if alpha < 0:\n",
    "        print(f\"Erro: alpha={alpha:.4f}, s={s:.4f}\")\n",
    "        alpha = s\n",
    "\n",
    "    return alpha\n",
    "\n",
    "# Loop principal do gradiente descendente\n",
    "for i in range(maxiter):\n",
    "    sol = solve_ivp(\n",
    "        lambda t, y: ODESYS(y, t, theta, sigma),\n",
    "        t_span, Y0, t_eval=t_eval, method='RK45')\n",
    "    Y = sol.y[:3].T\n",
    "\n",
    "    # Reshape sensitivities para 3 states × 2 parameters\n",
    "    sensitivities = sol.y[3:].T.reshape(-1, 3, 2)\n",
    "\n",
    "    current_cost = cost(Y)\n",
    "\n",
    "    error_history.append(current_cost)\n",
    "    par_history.append((theta, sigma))\n",
    "    alpha_history.append(0.0)\n",
    "\n",
    "    if abs((current_cost - prev_cost)/prev_cost) < tolerance and i > 0:\n",
    "        print(f\"Convergiu na iteração {i}\")\n",
    "        break\n",
    "\n",
    "    prev_cost = current_cost\n",
    "\n",
    "    # Chamando Linear Search\n",
    "    alpha = line_search(theta, sigma, grad_c, sensitivities, Y, current_cost)\n",
    "\n",
    "    # Atualizar os parâmetros (apenas 2 parâmetros)\n",
    "    theta -= alpha * (grad_c(Y) * sensitivities[:, :, 0]).sum()\n",
    "    sigma -= alpha * (grad_c(Y) * sensitivities[:, :, 1]).sum()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Iter {i}: theta={theta:.4f}, sigma={sigma:.4f}, alpha={alpha:.4f}, current_cost={current_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_theta = abs(theta - true_theta) / true_theta * 100\n",
    "error_sigma = abs(sigma - true_sigma) / true_sigma * 100\n",
    "\n",
    "print(f\"Valores estimados:   θ={theta:.4f}, γ={sigma:.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(\"RESULTADOS FINAIS:\")\n",
    "print(f\"Valores verdadeiros: θ={true_theta:.4f}, γ={true_sigma:.4f}\")\n",
    "print(f\"Valores estimados:   θ={theta:.4f}, γ={sigma:.4f}\")\n",
    "print(f\"Erro θ: {error_theta:.2f}%\")\n",
    "print(f\"Erro γ: {error_sigma:.2f}%\")\n",
    "print(f\"Custo final: {current_cost:.6f}\")\n",
    "print(f\"Iterações: {len(error_history)}\")\n",
    "\n",
    "# %%\n",
    "print(f\"Valores estimados:   θ={theta:.4f}, γ={sigma:.4f}\")\n",
    "print(f\"Custo final: {current_cost:.6f}\")\n",
    "print(f\"Iterações: {len(error_history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da evolução dos parâmetros durante a otimização\n",
    "par_history = np.array(par_history)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# Subplot 1: theta\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(par_history[:, 0], 'b-', linewidth=2, marker='o', markersize=4)\n",
    "plt.axhline(y=true_theta, color='r', linestyle='--', linewidth=2, label=f'Verdadeiro: {true_theta:.4f}')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Theta(θ)')\n",
    "plt.title('Evolução de theta(θ)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: gamma\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(par_history[:, 1], 'g-', linewidth=2, marker='s', markersize=4)\n",
    "plt.axhline(y=true_sigma, color='r', linestyle='--', linewidth=2, label=f'Verdadeiro: {true_sigma:.4f}')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Gamma(γ)')\n",
    "plt.title('Evolução de gamma(γ)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Observações vs modelo final\n",
    "sol_final = solve_ivp(\n",
    "    lambda t, y: ODESYS(y, t, theta, sigma),\n",
    "    t_span, Y0, t_eval=t_eval, method='RK45'\n",
    ")\n",
    "y_final = sol_final.y[:3].T\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(t_eval, y_obs[:, 0], alpha=0.7, label='S (observado)', color='blue', s=10)\n",
    "plt.scatter(t_eval, y_obs[:, 1], alpha=0.7, label='I (observado)', color='red', s=10)\n",
    "plt.scatter(t_eval, y_obs[:, 2], alpha=0.7, label='R (observado)', color='green', s=10)\n",
    "\n",
    "plt.plot(t_eval, y_final[:, 0], '--', label='S (modelo)', color='darkblue', linewidth=2)\n",
    "plt.plot(t_eval, y_final[:, 1], '--', label='I (modelo)', color='darkred', linewidth=2)\n",
    "plt.plot(t_eval, y_final[:, 2], '--', label='R (modelo)', color='darkgreen', linewidth=2)\n",
    "\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Proporção da população')\n",
    "plt.title('Dados observados vs Modelo ajustado')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
